{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import operator\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('../data/breast-cancer-wisconsin.data.txt')\n",
    "\n",
    "#preprocess data\n",
    "df = df.replace('?',-99999) #not vulnerable to outliers\n",
    "df = df.astype(float)\n",
    "df = df.drop(['id'],1)\n",
    "\n",
    "#Shuffle the Data\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create copy\n",
    "tf = df.copy()\n",
    "#tf = tf.drop('class',axis=1) #drop class\n",
    "\n",
    "#feature names\n",
    "features = tf.columns\n",
    "\n",
    "#Define the percentage of the data that you want to use for testing\n",
    "test_size = 0.2\n",
    "\n",
    "#Grabs the first (1-test_size) of the data\n",
    "train_data = tf[:-int(test_size*len(tf))]\n",
    "\n",
    "#Grabs the last (test_size) of the data\n",
    "test_data = tf[-int(test_size*len(tf)):]\n",
    "\n",
    "#save as value arrays\n",
    "#train_data = train_data.values\n",
    "#test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \n",
    "    #initialize parameters\n",
    "    def __init__(self, printing=False):\n",
    "        self.printing = printing\n",
    "    \n",
    "    #build model    \n",
    "    def fit(self, trainSet, testSet):\n",
    "        self.trainSet = trainSet\n",
    "        self.testSet = testSet\n",
    "        \n",
    "        class_summaries = self.class_summaries(self.trainSet)\n",
    "        \n",
    "        self.summaries = class_summaries\n",
    "        \n",
    "        return class_summaries\n",
    "    \n",
    "    #summarize class by mean and stdev\n",
    "    def class_summaries(self, dataset):\n",
    "        summaries = {}\n",
    "        \n",
    "        for cls in dataset['class'].unique():\n",
    "            cls_data = dataset[dataset['class'] == cls]\n",
    "            summary = cls_data.describe().loc[['mean','std']]\n",
    "            summaries[cls] = summary\n",
    "            \n",
    "        return summaries\n",
    "    \n",
    "    #find gaussian probability\n",
    "    def gaussian_probability(self, x, mean, std):\n",
    "        probability = scipy.stats.norm(mean, std).pdf(x)\n",
    "        return probability\n",
    "    \n",
    "    #calculate probabilities of testInstance belonging to each class\n",
    "    def class_probabilities(self, summaries, testInstance):\n",
    "        probabilities = {}\n",
    "\n",
    "        #for each class/summary...\n",
    "        for cls, classSummary in summaries.items():\n",
    "            probabilities[cls] = 1\n",
    "\n",
    "            #for each feature...\n",
    "            for i in range(np.shape(summaries[cls].values)[1] - 1):\n",
    "                mean = classSummary.iloc[0][i]\n",
    "                stdev = classSummary.iloc[1][i]\n",
    "                x = testInstance[i]\n",
    "\n",
    "                #apply chain rule of probabilities\n",
    "                probabilities[cls] *= self.gaussian_probability(x, mean, stdev)\n",
    "\n",
    "        return probabilities\n",
    "     \n",
    "    #predict class for datapoint\n",
    "    def class_predict(self, summaries, testInstance):\n",
    "        probabilities = self.class_probabilities(summaries, testInstance)\n",
    "        bestLabel, bestProb = None, -1\n",
    "        \n",
    "        for cls, probability in probabilities.items():\n",
    "            if bestLabel is None or probability > bestProb:\n",
    "                bestProb = probability\n",
    "                bestLabel = cls\n",
    "        \n",
    "        return bestLabel\n",
    "    \n",
    "    #make predictions\n",
    "    def predict(self):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(len(self.testSet)):\n",
    "            testInstance = self.testSet.iloc[i]\n",
    "            result = self.class_predict(self.summaries, testInstance)\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "        \n",
    "    #evaluate predictions\n",
    "    def score(self, predictions):\n",
    "        actual = pd.DataFrame(self.testSet)['class']\n",
    "        correct = sum(predictions == actual) \n",
    "        accuracy = correct / len(self.testSet)\n",
    "        return accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98561151079136688"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "summaries = nb.fit(train_data,test_data)\n",
    "predictions = nb.predict()\n",
    "nb.score(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
